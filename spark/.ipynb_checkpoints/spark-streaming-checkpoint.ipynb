{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meetup: Spark Streaming \n",
    "2016-21-09"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leading In...\n",
    "\n",
    "sql, streaming, graphx mlib are the four main packages \n",
    "\n",
    "#### term: rdd \n",
    "are resilient distributed dataset (parallelized lazyly evaluate directed acyclic graph of computation)\n",
    "\n",
    "each time you do a transformation, you get a new rdd back (immutable) -> concept called lineage\n",
    "\n",
    "there is nothing going on until you do an `action`, otherwise it's just keeping track of transformations\n",
    "\n",
    "#### setup\n",
    "data -> spark streaming -> spark engine \n",
    "\n",
    "where spark engine processes a bunch of data per 0.5 sec\n",
    "\n",
    "...spark streaming uses Dstreams\n",
    "#### term: dstream\n",
    "discretized stream\n",
    "\n",
    "window-based operation is the last hour of hashtags\n",
    "\n",
    "where a slid encompasses time 3, 4, 5 and each window is taken at a given interval such as each pair time (2, 4, 6)\n",
    "```\n",
    "ssc.textFileInput('filename')\n",
    "```\n",
    "\n",
    "#### term: sql library\n",
    "comes with 2 dsl: dataframes and sql\n",
    "spark.sparkCOntext.textFile('data/all-shakespear.txt').toDF('line')\n",
    "```\n",
    "spark.sql('enter query here')\n",
    "```\n",
    "\n",
    "... the spark sql api has several optimizations:\n",
    "##### 1 - term: catalyst\n",
    "its a query optimizer, sql will optimize the queries for you\n",
    "\n",
    "100 rules or so\n",
    "\n",
    "'can it be better than sql?' ... won't say yes to that\n",
    "\n",
    "rules such as 'pushes joins to the end of the task stack'\n",
    "\n",
    "you can inject your own rules (domain rules) into it\n",
    "\n",
    "##### 2 - tungsten\n",
    "processers are slowly advancing than RAM and ethernet or SSD ...\n",
    "\n",
    "memory management and binary processing\n",
    "\n",
    "cache aware computation\n",
    "- dsnt dreference to RAM when it doesn't have to\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark 2.0 is the Alpha Release of Structured Streaming\n",
    "note for inqtel: ad-hoc queries for kafka stream before it gets dumped into a database\n",
    "\n",
    "```\n",
    "spark =SparkSession\n",
    ".builder\n",
    ".appName('structuredStreamWordCount')\n",
    ".master('local')\n",
    ".getOrCreate()\n",
    "import spark.implicites._\n",
    "spark.readStream.text('somefile')\n",
    "query = wordCounts.WriteStream()\n",
    "query.awaitTermination()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source API has a requirement for replayability where you can scroll back and start reading from a given index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "idempotence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kafka Integration in 2.1 !\n",
    "\n",
    "Public API for sources and sinks\n",
    "\n",
    "ML integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dmitri Carpov is really good, explains well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.meetup.com/Montreal-Apache-Spark-Meetup/members/121418712/"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/4762441072963928/4075793835474818/2878426607513351/latest.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
